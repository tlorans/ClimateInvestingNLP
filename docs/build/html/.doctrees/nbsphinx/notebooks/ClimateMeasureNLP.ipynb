{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uF9JzVeKnmI4"
   },
   "source": [
    "# Quantifying Firm-Level Exposure to a Climate Theme with Natural Language Processing: a Simple Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A8CJ9ux3Xcke"
   },
   "source": [
    "Following Sautner et al. (2022) approach, one can build a firm-level theme exposure to a specific theme (in Sautner et al., climate risks exposure) based on text mining. \n",
    "\n",
    "More specifically, we can define the firm-level exposure to a theme as *the percentage of keywords from the firm's text (in the following of this proposal earnings call transcripts or business description) that are related (ie. semantically similar) to a list of specific theme keywords.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "deB5R77knv6A"
   },
   "source": [
    "## Keywords extraction and Theme-specific keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lQbkwA5Qc-Zi"
   },
   "source": [
    "We first need to extract, for each firm, a set of keywords $K_{i,t}$ from the firm specific text. We also need to define a set $S$ of theme-specific keywords to be compared with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sH8FPbDophDy"
   },
   "outputs": [],
   "source": [
    "!pip install keyphrase-vectorizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "02Bya4wpphxh"
   },
   "outputs": [],
   "source": [
    "from keyphrase_vectorizers import KeyphraseCountVectorizer  \n",
    "vectorizer = KeyphraseCountVectorizer(stop_words = 'english')\n",
    "\n",
    "firm_text = \"The profitable growth in the gas and low carbon electricity integrated value chains is one of the key axes of Total's strategy. In order to give more visibility to these businesses, a new reporting structure for the business segments’ financial information has been put in place, effective January 1, 2019 and organized around four business segments: Exploration & Production (EP), Integrated Gas, Renewables & Power segment (iGRP), Refining & Chemicals (RC) and Marketing & Services (MS). The iGRP segment spearheads Total’s ambitions in integrated gas (including LNG, liquefied natural gas) and low carbon electricity businesses. It consists of the upstream and midstream LNG activity that was previously reported in the EP segment (refer to the indicative list of assets in the Annex) and the activity previously reported in the Gas Renewables & Power segment. The new EP segment is adjusted accordingly\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2hkztWq3rrCJ",
    "outputId": "c8c0d57f-092d-49b2-8382-20e40ba822de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['key axes', 'services', 'natural gas', 'new ep segment',\n",
       "       'exploration', 'power segment', 'ambitions', 'activity',\n",
       "       'low carbon electricity businesses', 'business segments',\n",
       "       'refining', 'ms', 'value chains', 'lng', 'gas renewables', 'ep',\n",
       "       'indicative list', 'profitable growth', 'place', 'renewables',\n",
       "       'ep segment', 'businesses', 'integrated gas', 'order', 'strategy',\n",
       "       'more visibility', 'rc', 'effective january', 'production',\n",
       "       'low carbon electricity', 'annex', 'financial information',\n",
       "       'midstream lng activity', 'chemicals', 'igrp segment', 'marketing',\n",
       "       'new reporting structure', 'gas', 'assets', 'total'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = vectorizer.fit([firm_text]).get_feature_names_out()\n",
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3f5-yYo3wRZt",
    "outputId": "9165b158-d27e-49c8-deb9-4063d50cf5d5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['solar pv', 'wind technology', 'renewables equipment']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S = ['solar pv', 'wind technology','renewables equipment']\n",
    "S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c3lBlGlOquwJ"
   },
   "source": [
    "## Embeddings\n",
    "\n",
    "Once firm's keywords $K_{i,t}$ are extracted and the set of theme-specific keywords $S$ are defined, we need to transform those unstructured data (text) into a numerical representation. To do so, we use Sentence Transformer capacities to create numerical vector representation of the meanings of $K_{i,t}$ and keywords in $S$:\n",
    "\n",
    "\\begin{equation}\n",
    "Emb^{k_{i,t}} = ST(k_{i,t})\n",
    "\\end{equation}\n",
    "\n",
    "and \n",
    "\n",
    "\\begin{equation}\n",
    "Emb^{s} = ST(s)\n",
    "\\end{equation}\n",
    "\n",
    "Where $Emb^{k_{i,t}}$ and $Emb^{s}$ are the numerical vector representation (embeddings) of the keyword $k_{i,t}$ and the keyword $s$, performed with the Sentence Transformer model $ST()$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uLl4EXK1wp8u"
   },
   "outputs": [],
   "source": [
    "!pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JGkyCYFpwoaz"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "\n",
    "ST = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IEez4lX_w4zG",
    "outputId": "61295f1e-ee12-433d-84b6-341c4b2100d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([384])\n",
      "tensor([ 6.0319e-04, -4.7906e-02, -1.3035e-01, -7.0738e-02, -5.9981e-02,\n",
      "        -2.3404e-02,  3.2279e-02, -8.2857e-03,  7.3527e-02,  9.1478e-02,\n",
      "         1.1488e-01,  6.6241e-02,  1.1704e-02, -6.7941e-03, -1.5293e-02,\n",
      "         2.6211e-04, -9.4862e-02, -2.5783e-02, -5.4984e-02,  1.9077e-02,\n",
      "        -1.7698e-02, -8.5624e-02,  3.7961e-02, -9.3274e-03, -2.8578e-02,\n",
      "         4.0039e-02,  6.8037e-02,  9.6512e-02,  4.1532e-02, -3.9542e-02,\n",
      "        -2.8297e-02,  7.7898e-03, -8.0047e-03,  3.8723e-02, -1.3231e-01,\n",
      "         1.9708e-02,  5.8352e-02,  2.9194e-02, -5.1628e-02,  2.8699e-02,\n",
      "        -6.5272e-03,  4.1512e-02,  8.5519e-02,  3.4931e-02,  4.3499e-02,\n",
      "         1.0456e-01, -6.8079e-02, -4.3619e-02,  3.9288e-03, -7.3304e-04,\n",
      "        -1.4330e-02, -4.3029e-03, -7.0102e-02, -2.6189e-02,  2.5443e-02,\n",
      "         1.6860e-02, -1.9855e-02,  1.1232e-03,  8.1846e-02, -3.4303e-02,\n",
      "         2.7013e-02,  5.2045e-02, -7.3718e-03, -2.5660e-02, -5.9664e-03,\n",
      "         2.7971e-02, -5.2767e-02, -7.9512e-02, -9.9387e-02,  6.2026e-02,\n",
      "        -3.3658e-02, -8.4043e-02,  9.3570e-03, -1.1433e-01, -3.1001e-02,\n",
      "        -1.9453e-02, -2.2890e-02, -7.4868e-02,  1.3017e-02, -2.6641e-02,\n",
      "        -7.2699e-02,  2.7575e-02, -1.8862e-02,  1.3297e-01,  2.8072e-02,\n",
      "         6.1019e-02, -2.8116e-02,  2.5376e-03, -3.2326e-03,  2.1872e-02,\n",
      "         3.4381e-03, -2.1207e-02,  4.9859e-02,  2.3749e-02,  2.7290e-02,\n",
      "        -5.7494e-03,  8.0976e-02, -4.9740e-02, -7.0971e-02,  1.0174e-01,\n",
      "         2.2548e-02, -8.1329e-02,  1.3616e-02, -1.4752e-02, -7.1383e-03,\n",
      "         2.6850e-02,  4.9872e-02, -1.7436e-02, -4.7995e-02, -1.9420e-02,\n",
      "        -3.7335e-02,  1.1119e-02, -3.9378e-02,  6.1053e-03,  5.9105e-02,\n",
      "         3.5028e-02, -3.7214e-02,  1.0512e-02,  2.7275e-02, -2.8099e-02,\n",
      "         4.2189e-02, -7.9656e-03, -6.3284e-02,  5.8900e-02, -8.1370e-02,\n",
      "         5.4323e-03, -2.4179e-02, -2.5576e-33, -4.3884e-02,  6.8354e-02,\n",
      "        -3.6952e-03, -8.9474e-02, -3.5839e-02, -4.0436e-02, -5.8439e-02,\n",
      "        -4.9167e-03,  6.8180e-02,  1.4679e-01, -8.4061e-02,  4.2336e-02,\n",
      "        -1.2441e-02,  1.4736e-02,  4.1263e-02, -9.8096e-02,  8.8994e-02,\n",
      "         1.1955e-01, -1.1300e-01, -9.0212e-02, -3.6214e-02, -1.0135e-02,\n",
      "        -3.5100e-03, -1.1905e-02,  7.3957e-03,  9.8804e-02,  2.5448e-02,\n",
      "         3.2968e-03, -7.1482e-03, -1.1025e-02,  9.8673e-04,  6.3649e-02,\n",
      "        -7.5920e-02, -7.3323e-02, -3.2329e-02, -3.3275e-02,  1.1949e-02,\n",
      "        -4.7970e-03, -3.4881e-02,  1.9667e-02, -2.2067e-03, -3.8711e-02,\n",
      "        -2.4693e-02, -3.3023e-02,  1.8130e-02,  4.9609e-02,  5.2483e-02,\n",
      "         1.5481e-02,  3.1898e-02,  4.8397e-03, -2.5455e-02,  1.7212e-02,\n",
      "        -4.7140e-02, -3.2268e-02,  4.6685e-02, -2.2196e-03,  1.1297e-02,\n",
      "         3.5229e-02, -2.1023e-02,  3.6479e-03, -3.2116e-02, -7.3615e-02,\n",
      "         3.5769e-02,  3.4351e-02, -1.6073e-03, -4.9878e-03,  1.3705e-02,\n",
      "        -8.0440e-02,  8.2345e-03,  4.2787e-02, -7.8822e-02, -3.5565e-02,\n",
      "         9.4920e-03,  2.2536e-02, -4.1556e-02,  2.7755e-03, -2.7831e-02,\n",
      "        -1.2307e-02,  1.0239e-02, -2.1181e-02, -8.6555e-02,  8.7811e-02,\n",
      "        -9.5663e-02, -4.5663e-02,  5.6588e-02,  2.5552e-02,  1.5746e-02,\n",
      "        -4.0060e-02,  5.6614e-03, -1.4472e-02, -8.7304e-02, -3.4315e-02,\n",
      "        -3.9388e-02, -2.3290e-02, -4.8980e-02,  7.6562e-34, -5.8203e-02,\n",
      "         4.3894e-02, -2.2217e-02,  5.2253e-02, -5.6479e-02,  5.6716e-02,\n",
      "         4.6260e-02, -8.9913e-03, -1.0918e-02,  5.1986e-02,  4.4450e-03,\n",
      "        -6.5120e-03,  4.6033e-02, -8.4244e-02,  1.0962e-01, -8.8652e-03,\n",
      "        -8.5053e-02,  1.0775e-01, -1.3044e-02, -7.7940e-02,  2.2134e-05,\n",
      "        -8.2040e-02, -2.9821e-02,  3.1278e-02,  3.8800e-02,  9.1137e-02,\n",
      "         2.3193e-02,  3.5260e-02, -5.4488e-02,  2.2528e-02, -2.9126e-02,\n",
      "        -6.1534e-03,  4.5513e-04, -1.5260e-02,  4.4769e-03,  4.0083e-02,\n",
      "         1.9450e-03, -2.6282e-02, -1.0435e-01,  2.4503e-02, -4.9161e-03,\n",
      "         2.2369e-02,  1.0196e-01,  7.6014e-02, -6.3936e-02, -1.4797e-02,\n",
      "         3.4844e-02,  8.3217e-02, -2.1255e-02,  4.2084e-02,  2.8338e-03,\n",
      "         2.8771e-02,  4.7359e-02, -1.4181e-01, -5.1101e-02,  1.3638e-02,\n",
      "        -5.5205e-02,  6.7438e-03,  9.0382e-02, -2.2310e-02, -3.4229e-03,\n",
      "        -4.0894e-02,  2.4828e-02,  6.5463e-02,  1.7387e-02, -5.3055e-02,\n",
      "         9.2002e-02, -2.7910e-02, -4.7123e-02,  7.5017e-02,  5.6088e-02,\n",
      "         3.8105e-02,  2.9930e-02, -3.7540e-02,  3.1607e-02, -8.5717e-02,\n",
      "        -1.2737e-02, -1.8067e-02, -1.2325e-02, -5.3510e-03,  7.8701e-02,\n",
      "        -2.0912e-02,  7.1306e-02,  8.7455e-02, -2.7917e-02,  7.0674e-02,\n",
      "        -2.7644e-02,  4.7822e-02,  3.2145e-02,  5.4341e-02,  2.6188e-02,\n",
      "         3.0423e-02,  1.4170e-02,  2.5028e-02,  5.3790e-02, -1.1275e-08,\n",
      "        -4.9572e-02,  1.1138e-01,  8.6166e-03, -2.9381e-02, -3.8988e-02,\n",
      "        -7.4658e-03, -1.2223e-02,  5.3203e-02, -2.2746e-02, -3.0748e-02,\n",
      "         2.1745e-02, -8.4958e-03, -5.4263e-02,  5.2940e-03, -2.8448e-02,\n",
      "         4.2296e-02, -2.8996e-04,  3.2922e-02,  3.7901e-02,  2.3852e-02,\n",
      "         3.1369e-02, -1.5624e-03,  7.0010e-02,  9.4230e-03, -7.8551e-02,\n",
      "         1.6800e-02, -5.2656e-02,  1.3897e-01,  5.9427e-02,  7.9529e-02,\n",
      "         4.5043e-02, -2.1802e-02,  1.4607e-01, -7.5472e-03, -2.9905e-02,\n",
      "        -4.0346e-02, -5.3599e-02,  6.3155e-02, -1.4472e-02,  1.5306e-02,\n",
      "        -5.3410e-02, -5.4940e-02, -4.6256e-02, -1.7636e-02, -9.1280e-02,\n",
      "         1.1237e-01,  2.5239e-02,  2.3367e-02, -6.8188e-02, -6.5153e-02,\n",
      "        -2.9118e-02, -4.4626e-02,  6.4052e-02,  1.6805e-02, -3.0919e-02,\n",
      "         7.6303e-02,  2.4738e-02,  2.3109e-02,  4.0332e-02,  5.7550e-03,\n",
      "        -2.0040e-02,  3.6741e-02, -9.4886e-02, -3.8128e-02])\n"
     ]
    }
   ],
   "source": [
    "emb_K = ST.encode(K, convert_to_tensor=True)\n",
    "print(emb_K[0].shape)\n",
    "print(emb_K[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sUSWFcC-xXm4"
   },
   "outputs": [],
   "source": [
    "emb_S = ST.encode(S, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G5uJbj3MoilR"
   },
   "source": [
    "## Identifying Keywords Theme-Related with Cosine Similarity\n",
    "\n",
    "We want to be able to determine if the keyword $k_{i,t}$ is related to our theme, thanks to the theme-specific keywords.\n",
    "\n",
    "As we now have numerical vector representations of our keywords $Emb^{k_{i,t}}$ and $Emb^s$, we can apply principles from semantic search by determining the closeness of our two vectors. Recalling that dimensions of our vector representation relate to the underlying meaning of the keywords, computing the closeness of our vectors allows for determining the semantic similarity between our keywords. \n",
    "\n",
    "One way to do so is by computing the cosine similarity between our two vectors. The cosine similarity measures the cosine of the angle of those two vectors. The closer the cosine similarity to 1 is, the more related the keywords are:\n",
    "\n",
    "\\begin{equation}\n",
    "cos(\\theta_{k_{i,t},s}) = \\frac{Emb^{k_{i,t}} \\cdot Emb^s}{||Emb^{k_{i,t}}|| ||Emb^s||}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4McgvgESrj4T"
   },
   "source": [
    "For each keyword extracted from firm's text $k_{i,t}$, the cosine similarity is computed against each theme-specific keywords $s$. The maximum cosine similarity measure is retained, and then compared to a predefined threshold (0.6) in order to finally determined if the keyword is related to our theme:\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "  \\tau(k_{i,t})=\n",
    "  \\begin{cases}\n",
    "    0, & \\text{if}\\ cos(\\theta_{k_{i,t},s}) < 0.6 \\\\\n",
    "    1, & \\text{otherwise}\n",
    "  \\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "Where $\\tau(k_{i,t})$ corresponds to an indicator taking the value 1 if the keyword is related to our specific theme and 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tu-uXZw0x3_I",
    "outputId": "e27f9d05-4dd4-46f0-d3e0-59d572d561d5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'corpus_id': 1, 'score': 0.08907477557659149}],\n",
       " [{'corpus_id': 2, 'score': 0.2804577648639679}],\n",
       " [{'corpus_id': 2, 'score': 0.2923046946525574}],\n",
       " [{'corpus_id': 0, 'score': 0.11122070252895355}],\n",
       " [{'corpus_id': 0, 'score': 0.10033018887042999}],\n",
       " [{'corpus_id': 0, 'score': 0.2162817418575287}],\n",
       " [{'corpus_id': 0, 'score': 0.09399345517158508}],\n",
       " [{'corpus_id': 0, 'score': 0.2687630355358124}],\n",
       " [{'corpus_id': 2, 'score': 0.39827126264572144}],\n",
       " [{'corpus_id': 2, 'score': 0.12914493680000305}],\n",
       " [{'corpus_id': 2, 'score': 0.15724506974220276}],\n",
       " [{'corpus_id': 1, 'score': 0.1424086093902588}],\n",
       " [{'corpus_id': 2, 'score': 0.25599735975265503}],\n",
       " [{'corpus_id': 2, 'score': 0.14899525046348572}],\n",
       " [{'corpus_id': 2, 'score': 0.6965174674987793}],\n",
       " [{'corpus_id': 0, 'score': 0.18591859936714172}],\n",
       " [{'corpus_id': 2, 'score': 0.08812528103590012}],\n",
       " [{'corpus_id': 2, 'score': 0.19480028748512268}],\n",
       " [{'corpus_id': 0, 'score': 0.15173721313476562}],\n",
       " [{'corpus_id': 2, 'score': 0.7917177081108093}],\n",
       " [{'corpus_id': 0, 'score': 0.14508482813835144}],\n",
       " [{'corpus_id': 2, 'score': 0.25476109981536865}],\n",
       " [{'corpus_id': 0, 'score': 0.22349005937576294}],\n",
       " [{'corpus_id': 2, 'score': 0.09128467738628387}],\n",
       " [{'corpus_id': 2, 'score': 0.13581551611423492}],\n",
       " [{'corpus_id': 1, 'score': 0.14822091162204742}],\n",
       " [{'corpus_id': 2, 'score': 0.15621855854988098}],\n",
       " [{'corpus_id': 1, 'score': 0.09564703702926636}],\n",
       " [{'corpus_id': 2, 'score': 0.27780526876449585}],\n",
       " [{'corpus_id': 2, 'score': 0.3770102858543396}],\n",
       " [{'corpus_id': 0, 'score': 0.08056971430778503}],\n",
       " [{'corpus_id': 2, 'score': 0.06822887808084488}],\n",
       " [{'corpus_id': 2, 'score': 0.20004017651081085}],\n",
       " [{'corpus_id': 0, 'score': 0.2466813027858734}],\n",
       " [{'corpus_id': 2, 'score': 0.10576629638671875}],\n",
       " [{'corpus_id': 0, 'score': 0.2104777693748474}],\n",
       " [{'corpus_id': 0, 'score': 0.10618101060390472}],\n",
       " [{'corpus_id': 0, 'score': 0.2792923152446747}],\n",
       " [{'corpus_id': 2, 'score': 0.2769312262535095}],\n",
       " [{'corpus_id': 0, 'score': 0.1651279330253601}]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hits = util.semantic_search(emb_K, emb_S, top_k=1)\n",
    "hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZMAd6qiry1Kf",
    "outputId": "c1b86832-2751-4678-cb9f-631ac9057f3c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2804577648639679"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hits[1][0]['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "06-yBQTcynk5",
    "outputId": "b8a73909-1f2c-45ab-96a2-1c3ae7f17083"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gas renewables' 'renewables']\n"
     ]
    }
   ],
   "source": [
    "T = []\n",
    "\n",
    "for i in range(len(hits)):\n",
    "  if hits[i][0]['score'] >= 0.6:\n",
    "    T.append(i)\n",
    "\n",
    "\n",
    "print(K[T])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xeFg9bc6o5kF"
   },
   "source": [
    "## Computing Theme Exposure\n",
    "\n",
    "Finally, we can compute our theme exposure such as:\n",
    "\n",
    "\\begin{equation}\n",
    "Exposure_{i,t} = \\frac{1}{K_{i,t}}\\sum_{k}^{K_{i,t}}\\tau(k_{i,t})\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Di6F0QMndFc",
    "outputId": "2c5a7ae7-6687-4917-ba31-96b831e52cd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05\n"
     ]
    }
   ],
   "source": [
    "Exposure = len(T) / len(K)\n",
    "print(Exposure)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
